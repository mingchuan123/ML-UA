{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Data cleaning for the words in text\n",
    "def review_words(review):\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    snowball = SnowballStemmer('english')\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #print(review_text)\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    letters = regex.sub(' ',review_text)\n",
    "    #print(letters)\n",
    "    words = letters.lower().split()\n",
    "    #print(words)\n",
    "    stops = set(stopwords.words('english'))\n",
    "    meaningful_words = [w for w in words if w not in stops]\n",
    "    lemmatized_words = [lmtzr.lemmatize(w) for w in meaningful_words]\n",
    "    #print(lemmatized_words[0])\n",
    "    stemmed_words = [snowball.stem(w) for w in lemmatized_words]\n",
    "    output_words = ' '.join(stemmed_words)\n",
    "    \n",
    "    return output_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Send all the reviews in a list\n",
    "def review_set(file):\n",
    "    data = pd.read_csv(file, header = 0, delimiter = '\\t', quoting = 3)\n",
    "    raw_review = data['review']\n",
    "    size = len(data['review'])\n",
    "    review_all = []\n",
    "    for i in range(size):\n",
    "        review_clean = review_words(raw_review[i])\n",
    "        review_all.append(review_clean)\n",
    "    if 'sentiment' in data.columns.values:        \n",
    "        raw_sentiment = data['sentiment']\n",
    "        print(review_all[:3])\n",
    "        return review_all, raw_sentiment\n",
    "    else:\n",
    "        return review_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count words frequency for each review\n",
    "def feature_set(data):\n",
    "    vectorizer = CountVectorizer(max_features = 50)\n",
    "    data_features = vectorizer.fit_transform(data)\n",
    "    name = vectorizer.get_feature_names()\n",
    "    features = data_features.toarray()\n",
    "    return features, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read data from labeledTrainData\n",
    "text,sentiment = review_set('labeledTrainData.tsv')\n",
    "text = np.array(text)\n",
    "features,names = feature_set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaomingchuan/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/zhaomingchuan/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stuff go moment mj start listen music watch odd documentari watch wiz watch moonwalk mayb want get certain insight guy thought realli cool eighti mayb make mind whether guilti innoc moonwalk part biographi part featur film rememb go see cinema origin releas subtl messag mj feel toward press also obvious messag drug bad kay visual impress cours michael jackson unless remot like mj anyway go hate find bore may call mj egotist consent make movi mj fan would say made fan true realli nice actual featur film bit final start minut exclud smooth crimin sequenc joe pesci convinc psychopath power drug lord want mj dead bad beyond mj overheard plan nah joe pesci charact rant want peopl know suppli drug etc dunno mayb hate mj music lot cool thing like mj turn car robot whole speed demon sequenc also director must patienc saint came film kiddi bad sequenc usual director hate work one kid let alon whole bunch perform complex danc scene bottom line movi peopl like mj one level anoth think peopl stay away tri give wholesom messag iron mj bestest buddi movi girl michael jackson truli one talent peopl ever grace planet guilti well attent gave subject hmmm well know peopl differ behind close door know fact either extrem nice stupid guy one sickest liar hope latter', 'classic war world timothi hine entertain film obvious go great effort length faith recreat h g well classic book mr hine succeed watch film appreci fact standard predict hollywood fare come everi year e g spielberg version tom cruis slightest resembl book obvious everyon look differ thing movi envis amateur critic look critic everyth other rate movi import base like entertain peopl never agre critic enjoy effort mr hine put faith h g well classic novel found entertain made easi overlook critic perceiv shortcom', 'film start manag nichola bell give welcom investor robert carradin primal park secret project mutat primal anim use fossil dna like jurassik park scientist resurrect one natur fearsom predat sabretooth tiger smilodon scientif ambit turn dead howev high voltag fenc open creatur escap begin savag stalk prey human visitor tourist scientif meanwhil youngster enter restrict area secur center attack pack larg pre histor anim deadlier bigger addit secur agent staci haiduk mate brian wimmer fight hard carnivor smilodon sabretooth cours real star star astound terrifi though convinc giant anim savag stalk prey group run afoul fight one natur fearsom predat furthermor third sabretooth danger slow stalk victim movi deliv good lot blood gore behead hair rais chill full scare sabretooth appear mediocr special effect stori provid excit stir entertain result quit bore giant anim major made comput generat seem total lousi middl perform though player react appropri becom food actor give vigor physic perform dodg beast run bound leap dangl wall pack ridicul final dead scene small kid realist gori violent attack scene film sabretooth smilodon follow sabretooth jame r hickox vanessa angel david keith john rhys davi much better bc roland emmerich steven strait cliff curti camilla bell motion pictur fill bloodi moment bad direct georg miller origin take mani element previous film miller australian director usual work televis tidal wave journey center earth mani other occasion cinema man snowi river zeus roxann robinson cruso rate averag bottom barrel']\n"
     ]
    }
   ],
   "source": [
    "#Read data from labeledTrainData\n",
    "text,sentiment = review_set('labeledTrainData.tsv')\n",
    "text = np.array(text)\n",
    "features,names = feature_set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train classifier\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest = forest.fit(features,sentiment)\n",
    "#svc = SVC(kernel = 'linear')\n",
    "#svc.fit(features,sentiment)\n",
    "#bayes = GaussianNB()\n",
    "#bayes = bayes.fit(features,sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaomingchuan/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/zhaomingchuan/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#Read Test Data and extract features\n",
    "data = review_set('testData.tsv')\n",
    "test,names = feature_set(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make predictions on test data\n",
    "k = pd.read_csv('testData.tsv',header = 0, delimiter = '\\t', quoting = 3)\n",
    "result = forest.predict(test)\n",
    "#result = bayes.predict(test)\n",
    "output = pd.DataFrame({'id':k['id'],'sentiment':result})\n",
    "output.to_csv('Bag_of_Words_model_x.csv', index=False,quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
